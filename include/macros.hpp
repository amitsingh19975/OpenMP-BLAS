#if !defined(AMT_BENCHMARK_MACROS_HPP)
#define AMT_BENCHMARK_MACROS_HPP

#if (!defined(__GNUC__) && !defined(__clang__))
    #define AMT_HAS_NO_INLINE_ASSEMBLY
#endif

#define AMT_ALWAYS_INLINE __attribute__((always_inline))
#define MiB(SIZE) SIZE / (1<<20)
#define KiB(SIZE) SIZE / (1<<10)

    
#define AMT_UNROLL_LOOP1_IMPL(OFFSET,...)           \
    AMT_UNROLL_STATEMENT((OFFSET + 0),__VA_ARGS__)      
    
#define AMT_UNROLL_LOOP2_IMPL(OFFSET,...)           \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 0),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 1),__VA_ARGS__)      
    
#define AMT_UNROLL_LOOP4_IMPL(OFFSET,...)           \
    AMT_UNROLL_LOOP2_IMPL((OFFSET + 0),__VA_ARGS__) \
    AMT_UNROLL_LOOP2_IMPL((OFFSET + 2),__VA_ARGS__) 

#define AMT_UNROLL_LOOP8_IMPL(OFFSET,...)           \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 0),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 1),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 2),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 3),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 4),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 5),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 6),__VA_ARGS__) \
    AMT_UNROLL_LOOP1_IMPL((OFFSET + 7),__VA_ARGS__)     
    // C[I] += A[I + W * (7+J)] * b[7 + J];

#define AMT_UNROLL_LOOP16_IMPL(OFFSET,...)          \
    AMT_UNROLL_LOOP8_IMPL(OFFSET,__VA_ARGS__)       \
    AMT_UNROLL_LOOP8_IMPL((OFFSET + 8),__VA_ARGS__)

#define AMT_UNROLL_LOOP32_IMPL(OFFSET,...)          \
    AMT_UNROLL_LOOP16_IMPL(OFFSET,__VA_ARGS__)      \
    AMT_UNROLL_LOOP16_IMPL((OFFSET + 16),__VA_ARGS__)

#define AMT_UNROLL_LOOP64_IMPL(OFFSET,...)          \
    AMT_UNROLL_LOOP32_IMPL(OFFSET,__VA_ARGS__)      \
    AMT_UNROLL_LOOP32_IMPL((OFFSET + 32),__VA_ARGS__)

#define AMT_UNROLL_LOOP128_IMPL(OFFSET,...)         \
    AMT_UNROLL_LOOP64_IMPL(OFFSET,__VA_ARGS__)      \
    AMT_UNROLL_LOOP64_IMPL((OFFSET + 64),__VA_ARGS__)

#define AMT_UNROLL_LOOP256_IMPL(OFFSET,...)         \
    AMT_UNROLL_LOOP128_IMPL(OFFSET,__VA_ARGS__)     \
    AMT_UNROLL_LOOP128_IMPL((OFFSET + 128),__VA_ARGS__)

#define AMT_UNROLL_LOOP512_IMPL(OFFSET,...)         \
    AMT_UNROLL_LOOP256_IMPL(OFFSET,__VA_ARGS__)     \
    AMT_UNROLL_LOOP256_IMPL((OFFSET + 256),__VA_ARGS__)

#define AMT_UNROLL_LOOP1(...) AMT_UNROLL_LOOP1_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP2(...) AMT_UNROLL_LOOP2_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP4(...) AMT_UNROLL_LOOP4_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP8(...) AMT_UNROLL_LOOP8_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP16(...) AMT_UNROLL_LOOP16_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP32(...) AMT_UNROLL_LOOP32_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP64(...) AMT_UNROLL_LOOP64_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP128(...) AMT_UNROLL_LOOP128_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP256(...) AMT_UNROLL_LOOP256_IMPL(0,__VA_ARGS__)
#define AMT_UNROLL_LOOP512(...) AMT_UNROLL_LOOP512_IMPL(0,__VA_ARGS__)

#endif // AMT_BENCHMARK_MACROS_HPP
